{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"model.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","source":["### Objective\n","This project tries to create new jazz music using deep learning Machine Learning models, in particular the RNN model (Recurrent Neural Network), which has the capability to learn from a sequence of past patterns in time to inform its next prediction."],"metadata":{"id":"lbNhs_IFfkEH"},"id":"lbNhs_IFfkEH"},{"cell_type":"markdown","source":["### Data\n","We will use 5 jazz song covers by Doug McKenzie downloaded from [his website](https://bushgrafts.com/midi/). These are predominantly piano covers, some of which have light accompaniments of other instruments such as bass guitar.\n","\n","They are stored and ingested in MIDI format (Musical Instrument Digital Interface), which is a format used to store instructions to play music, such as the note (a single sound), the pitch (the frequency of the sound), and more."],"metadata":{"id":"pwyS3WuYlNwt"},"id":"pwyS3WuYlNwt"},{"cell_type":"markdown","metadata":{"id":"O2-ZlR6TwwGw"},"source":["Where NLP models (Natural Language Processing) ingest words as training inputs, music uses notes as inputs.\n","\n","Hence our first step is to extract the notes and chords (several notes played at the same time) from the MIDI files. We will use the library [Music21 from MIT](http://web.mit.edu/music21/) to do this.\n","\n","Before we continue, I would like to credit the works by [Shubham Gupta](https://www.hackerearth.com/blog/developers/jazz-music-using-deep-learning/) and [Sigurður Skúli](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5), which I've used as references."],"id":"O2-ZlR6TwwGw"},{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"BVE0v-XklwTL"},"id":"BVE0v-XklwTL"},{"cell_type":"code","metadata":{"id":"e4b2dfb0","executionInfo":{"status":"ok","timestamp":1639666786357,"user_tz":-480,"elapsed":3948,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}}},"source":["# Importing all the libraries used\n","import glob\n","import pickle\n","import numpy as np\n","import pandas as pd\n","from music21 import converter, instrument, note, stream, chord\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.layers import Activation\n","from keras.layers import BatchNormalization as BatchNorm\n","from keras.utils import np_utils\n","from keras.callbacks import ModelCheckpoint"],"id":"e4b2dfb0","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x5exrOhu_l50","executionInfo":{"status":"ok","timestamp":1639666816158,"user_tz":-480,"elapsed":19577,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}},"outputId":"83391b1b-f596-459b-dc2c-e56f0f329364"},"source":["# Linking notebook to the google drive folder where the files are stored - This step is needed because the project is created in Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"x5exrOhu_l50","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### Extract Data"],"metadata":{"id":"NLf7dPGelEP8"},"id":"NLf7dPGelEP8"},{"cell_type":"markdown","source":["First, we have to extract the notes and chords from our MIDI files.\n","\n"],"metadata":{"id":"hVHYYqbEwWdK"},"id":"hVHYYqbEwWdK"},{"cell_type":"code","metadata":{"id":"87d08e76","executionInfo":{"status":"ok","timestamp":1639666826456,"user_tz":-480,"elapsed":338,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}}},"source":["# Parse all notes from the midi files in the songs folder\n","def extract_notes():\n","    notes = []\n","\n","    for file in glob.glob(\"/content/drive/MyDrive/Colab Notebooks/songs/*.mid\"):\n","        midi = converter.parse(file)\n","        print(\"Parsing %s\" % file)\n","        notes_to_parse = None\n","\n","        try: # partition each instrument into different parts\n","            instr = instrument.partitionByInstrument(midi)\n","            notes_to_parse = instr.parts[0].recurse() \n","        except: # file has notes in a flat structure\n","            notes_to_parse = midi.flat.notes\n","\n","        for element in notes_to_parse:\n","            if isinstance(element, note.Note):\n","              #if the element is a note, extract the pitch\n","                notes.append(str(element.pitch))\n","            elif isinstance(element, chord.Chord):\n","              #if the element is a chord, extract the normal order of the chord (a list of integers)\n","                notes.append('.'.join(str(n) for n in element.normalOrder))\n","\n","    # store the parsed output into an external file\n","    with open('/content/drive/MyDrive/Colab Notebooks/model/data/notes', 'wb') as filepath:\n","        pickle.dump(notes, filepath)\n","\n","    return notes"],"id":"87d08e76","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HgCpwbR5_-oc","executionInfo":{"status":"ok","timestamp":1639666871215,"user_tz":-480,"elapsed":25614,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}},"outputId":"4978c5db-5619-46c0-ed3c-c0d1ec30968b"},"source":["# Extract all notes from the 5 songs and store them into an output file called 'notes'\n","extract_notes()"],"id":"HgCpwbR5_-oc","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Parsing /content/drive/MyDrive/Colab Notebooks/songs/afine-2.mid\n","Parsing /content/drive/MyDrive/Colab Notebooks/songs/A Sleepin' Bee.mid\n","Parsing /content/drive/MyDrive/Colab Notebooks/songs/AfterYou.mid\n","Parsing /content/drive/MyDrive/Colab Notebooks/songs/accustomed.mid\n"]},{"output_type":"execute_result","data":{"text/plain":["['B-4',\n"," 'F4',\n"," '0.2',\n"," '0.2',\n"," 'F4',\n"," 'F3',\n"," 'G#4',\n"," '11.2',\n"," 'G4',\n"," 'G5',\n"," 'F3',\n"," 'F5',\n"," 'G#4',\n"," 'B4',\n"," 'D5',\n"," 'G4',\n"," 'F3',\n"," 'G5',\n"," 'E-4',\n"," 'A4',\n"," 'A3',\n"," '9.2',\n"," 'F3',\n"," 'A4',\n"," 'F#5',\n"," 'A6',\n"," 'D6',\n"," '6.9',\n"," 'E-4',\n"," 'A3',\n"," 'F3',\n"," 'B-3',\n"," 'C#4',\n"," 'B-4',\n"," '4',\n"," 'C#5',\n"," 'A5',\n"," 'F3',\n"," '10.1',\n"," '1.4.7',\n"," '1.7',\n"," '1.4.7.9',\n"," '10.1',\n"," 'E4',\n"," 'F3',\n"," '5.9',\n"," 'D5',\n"," 'D4',\n"," 'F3',\n"," 'F4',\n"," 'A4',\n"," 'F3',\n"," 'F2',\n"," 'F1',\n"," 'F4',\n"," '9.0.2.5',\n"," '10.0',\n"," 'C5',\n"," '5.10',\n"," 'F2',\n"," 'F1',\n"," '3.5',\n"," '7.10',\n"," 'E-4',\n"," 'F3',\n"," '7.10',\n"," 'E-4',\n"," 'F3',\n"," 'E-4',\n"," 'D5',\n"," '6.9',\n"," 'G4',\n"," 'D6',\n"," 'F3',\n"," '0.3.7',\n"," 'C5',\n"," 'F3',\n"," 'F4',\n"," 'B-4',\n"," '0.2',\n"," 'F4',\n"," 'A4',\n"," 'F3',\n"," 'B-4',\n"," 'A4',\n"," 'F4',\n"," 'B-4',\n"," '0.2',\n"," 'C5',\n"," 'F3',\n"," '10.0.3.5',\n"," '10.0.5',\n"," '9.0.2',\n"," 'A3',\n"," 'F4',\n"," '2.8',\n"," 'G#2',\n"," '5.7.11',\n"," '2.4',\n"," 'G2',\n"," 'F4',\n"," '0.3.6.9',\n"," 'F3',\n"," 'B2',\n"," '3.5',\n"," 'B-3',\n"," 'G3',\n"," 'C1',\n"," '3.4.8',\n"," 'C5',\n"," 'B-3',\n"," 'A3',\n"," '2.3.5',\n"," 'A4',\n"," 'F3',\n"," '11.1.3.5.8',\n"," '5.9',\n"," '0.2.6',\n"," 'G2',\n"," 'B-3',\n"," 'F3',\n"," 'G2',\n"," 'G3',\n"," 'D4',\n"," 'G4',\n"," '6.10',\n"," 'F#4',\n"," 'G4',\n"," 'F#4',\n"," 'D4',\n"," 'G4',\n"," 'G#4',\n"," 'F3',\n"," 'G4',\n"," 'D4',\n"," 'B-3',\n"," 'F#4',\n"," '5.10',\n"," 'F4',\n"," 'D4',\n"," 'E4',\n"," '8.11',\n"," 'F3',\n"," 'D3',\n"," 'G2',\n"," '11.3.5',\n"," 'B2',\n"," 'G#3',\n"," 'D4',\n"," '0.6',\n"," '9.0.2',\n"," '9.2',\n"," 'F#4',\n"," 'D4',\n"," 'B-3',\n"," 'E4',\n"," 'D5',\n"," 'E4',\n"," 'G4',\n"," 'B-3',\n"," 'E-4',\n"," 'A3',\n"," 'D4',\n"," '7.11',\n"," 'F2',\n"," 'C5',\n"," 'D5',\n"," 'F#4',\n"," 'D4',\n"," 'A3',\n"," 'E-3',\n"," 'A3',\n"," 'B-4',\n"," 'F4',\n"," '0.2',\n"," 'B-4',\n"," 'A4',\n"," 'B-4',\n"," 'F3',\n"," 'B-4',\n"," '0.5',\n"," 'D4',\n"," 'C4',\n"," 'D4',\n"," 'F4',\n"," 'F3',\n"," '7.8',\n"," 'G#3',\n"," '11.2',\n"," 'F5',\n"," '7.8',\n"," 'F5',\n"," 'F3',\n"," '5',\n"," 'F5',\n"," 'D4',\n"," 'B3',\n"," 'F3',\n"," 'D5',\n"," 'E-4',\n"," 'C4',\n"," 'A3',\n"," 'A4',\n"," 'F3',\n"," 'E-4',\n"," 'C4',\n"," 'A3',\n"," 'F3',\n"," 'B-3',\n"," 'C#4',\n"," 'G5',\n"," 'A5',\n"," 'C#6',\n"," 'E4',\n"," 'E6',\n"," 'A6',\n"," 'F3',\n"," '10.1',\n"," 'G6',\n"," 'E4',\n"," 'C#6',\n"," 'E6',\n"," 'G5',\n"," 'F3',\n"," 'A6',\n"," 'D4',\n"," '2',\n"," 'A3',\n"," 'D6',\n"," 'F3',\n"," 'A3',\n"," 'D5',\n"," '2',\n"," 'F3',\n"," '10.11',\n"," '0.1',\n"," 'B5',\n"," 'C6',\n"," 'B-5',\n"," 'F3',\n"," 'B-3',\n"," 'D4',\n"," 'F2',\n"," 'D4',\n"," 'E-4',\n"," 'D4',\n"," 'E-4',\n"," 'D4',\n"," 'C#4',\n"," 'D4',\n"," 'E-4',\n"," 'E4',\n"," 'F3',\n"," 'F4',\n"," 'G3',\n"," 'F2',\n"," '3.5',\n"," 'B-4',\n"," 'G4',\n"," 'F4',\n"," 'F3',\n"," 'D4',\n"," 'D5',\n"," 'F#5',\n"," '3.7',\n"," 'A5',\n"," 'D6',\n"," 'F3',\n"," 'E-4',\n"," 'C6',\n"," 'A5',\n"," 'F4',\n"," 'B-5',\n"," '0.2',\n"," 'A5',\n"," 'B-5',\n"," 'F3',\n"," 'A5',\n"," '0.2',\n"," 'F4',\n"," 'B-5',\n"," 'F3',\n"," 'C6',\n"," '7.8',\n"," '2',\n"," 'G#3',\n"," 'A5',\n"," '6.8.1',\n"," 'C#4',\n"," 'G3',\n"," '5.7.0',\n"," 'C5',\n"," 'F#3',\n"," '11.4',\n"," '5.11',\n"," '6.8.10',\n"," 'F5',\n"," '4.9',\n"," '3.8',\n"," '3.7',\n"," '3.7',\n"," 'B-2',\n"," 'C4',\n"," 'C#4',\n"," 'B-3',\n"," 'E-4',\n"," 'F4',\n"," 'G4',\n"," 'F4',\n"," 'A4',\n"," 'B3',\n"," 'B-4',\n"," 'B4',\n"," 'C5',\n"," 'B-3',\n"," '10.1.4',\n"," 'G4',\n"," '9.0',\n"," 'F#4',\n"," '3.5.8',\n"," '7.10',\n"," 'C#5',\n"," 'E4',\n"," 'F#5',\n"," '3.9',\n"," 'E-5',\n"," 'C5',\n"," 'A3',\n"," '0.5',\n"," 'F4',\n"," 'D3',\n"," 'F4',\n"," 'D3',\n"," '11.1',\n"," 'G2',\n"," 'F3',\n"," '11.2',\n"," '11.2.5',\n"," 'D3',\n"," 'B2',\n"," '7.10.0.3',\n"," '0.3.7',\n"," '0.3.7',\n"," '0.3.6.7',\n"," 'E2',\n"," '3.5',\n"," '9.0.3',\n"," 'F1',\n"," '5.9.0',\n"," '9.1.4',\n"," 'A4',\n"," '10',\n"," 'B-3',\n"," 'B-3',\n"," 'B-3',\n"," '9.1.4',\n"," 'B-3',\n"," 'B-3',\n"," 'A3',\n"," 'C#4',\n"," 'E4',\n"," 'A4',\n"," '4.9',\n"," 'B-3',\n"," 'E4',\n"," '4.9.10',\n"," '9.1.4',\n"," 'B-3',\n"," 'E4',\n"," '10.1',\n"," 'A3',\n"," 'B-3',\n"," 'D5',\n"," 'F3',\n"," 'F2',\n"," 'B-3',\n"," 'F3',\n"," 'G3',\n"," 'A3',\n"," '5.10',\n"," 'G3',\n"," 'A3',\n"," 'F2',\n"," 'B3',\n"," 'G3',\n"," 'G#3',\n"," 'B-3',\n"," 'F3',\n"," 'B3',\n"," 'C#4',\n"," 'D4',\n"," 'E4',\n"," 'F2',\n"," 'F4',\n"," 'G4',\n"," 'G#4',\n"," 'B-4',\n"," '5.11',\n"," 'C5',\n"," 'C#5',\n"," 'D5',\n"," '2.3.6',\n"," 'A4',\n"," 'D4',\n"," 'F#4',\n"," 'E-4',\n"," 'F3',\n"," 'E-4',\n"," 'A4',\n"," 'D5',\n"," 'F#5',\n"," 'F4',\n"," 'A5',\n"," 'F3',\n"," 'B-3',\n"," 'C#4',\n"," 'A4',\n"," '1.4',\n"," '4',\n"," 'A5',\n"," 'F3',\n"," 'G5',\n"," '1.7',\n"," 'E5',\n"," 'E4',\n"," '10.1',\n"," 'C#5',\n"," 'E4',\n"," 'G4',\n"," 'F3',\n"," 'A5',\n"," 'D4',\n"," 'A3',\n"," 'D5',\n"," 'G#4',\n"," 'A4',\n"," 'F4',\n"," 'D5',\n"," 'F3',\n"," '7.9',\n"," 'D4',\n"," 'F4',\n"," 'A3',\n"," 'D4',\n"," 'F4',\n"," 'F3',\n"," '10.0.2.5',\n"," 'F4',\n"," 'C6',\n"," 'F3',\n"," '7.10',\n"," 'B-3',\n"," 'D4',\n"," 'F4',\n"," 'F3',\n"," 'D4',\n"," '3.5.10',\n"," 'F3',\n"," '3.5.7.10',\n"," 'F2',\n"," 'F1',\n"," '7.10',\n"," 'F3',\n"," 'C4',\n"," '3.6',\n"," 'D4',\n"," 'A4',\n"," 'D5',\n"," '3.6',\n"," '3.9',\n"," 'C5',\n"," '0.6',\n"," 'A3',\n"," 'E-4',\n"," 'G#4',\n"," '8.9.11',\n"," '8.10',\n"," '2.7',\n"," '2.5.8',\n"," 'G3',\n"," '4.6.9',\n"," '9',\n"," 'C#4',\n"," '8.10',\n"," '7.8.10',\n"," '2.5.7',\n"," 'E-4',\n"," '8.0',\n"," '7.8.9.0',\n"," '2.7',\n"," '8.10',\n"," '10',\n"," 'F#6',\n"," '4.6',\n"," '7.9.11',\n"," 'C#4',\n"," '0.5',\n"," '8.0.3',\n"," 'F#3',\n"," '2.7',\n"," 'G5',\n"," '11.4',\n"," 'F3',\n"," 'F3',\n"," '1.6',\n"," 'C#6',\n"," '0.5',\n"," '5.10',\n"," 'G4',\n"," '2.3',\n"," 'D5',\n"," 'C#5',\n"," 'C5',\n"," 'B4',\n"," '2.3',\n"," 'G4',\n"," 'E-4',\n"," 'F3',\n"," 'E-4',\n"," '11.0',\n"," 'C5',\n"," 'B4',\n"," 'G4',\n"," 'B-4',\n"," 'C5',\n"," 'B-4',\n"," 'G4',\n"," 'E-4',\n"," 'A4',\n"," 'F4',\n"," '0.3',\n"," 'D3',\n"," 'C4',\n"," '2.6',\n"," 'B-3',\n"," 'G2',\n"," 'G3',\n"," 'D4',\n"," '7.9',\n"," '6.10',\n"," 'D4',\n"," 'D4',\n"," 'B-3',\n"," 'F3',\n"," 'F#4',\n"," 'G4',\n"," 'A4',\n"," 'D4',\n"," '7.10',\n"," 'D4',\n"," '7.9.2',\n"," '6.8.1',\n"," 'C#4',\n"," '5.7.0',\n"," 'C4',\n"," '11.4',\n"," 'F4',\n"," 'B3',\n"," 'E-5',\n"," '4.10',\n"," 'B-3',\n"," 'F#4',\n"," 'D4',\n"," 'D5',\n"," 'B-3',\n"," 'C3',\n"," 'A4',\n"," 'F#4',\n"," 'D4',\n"," 'B-3',\n"," 'C3',\n"," 'G4',\n"," '10.2',\n"," '10.2',\n"," 'C3',\n"," '3.7.11',\n"," 'D4',\n"," 'E-4',\n"," '7.11',\n"," 'B3',\n"," '3.7',\n"," 'B-4',\n"," 'A3',\n"," 'E-4',\n"," 'A4',\n"," 'C4',\n"," 'D4',\n"," 'F3',\n"," 'F4',\n"," 'F2',\n"," 'F2',\n"," '5.7',\n"," '5.7',\n"," 'F3',\n"," 'A3',\n"," '5.10',\n"," 'F2',\n"," 'B-3',\n"," '8.11',\n"," '5.8',\n"," 'C#4',\n"," '11.2.5',\n"," 'F3',\n"," 'B3',\n"," 'G#3',\n"," '5.8.11',\n"," '11.2',\n"," 'B3',\n"," 'F3',\n"," '5.8.11',\n"," '11.2.5',\n"," 'F2',\n"," '8.11.2',\n"," 'F4',\n"," '2.3',\n"," '2.6.9',\n"," '2.6.9',\n"," '9.2',\n"," 'F2',\n"," 'F2',\n"," '2.3.6.9',\n"," '3.9',\n"," 'D5',\n"," '2.6.9',\n"," 'E-3',\n"," '5.7',\n"," '1.4',\n"," '4.7',\n"," 'G4',\n"," 'F3',\n"," 'F2',\n"," '1.4.7.10',\n"," 'F2',\n"," 'E3',\n"," 'E3',\n"," '10.1.4',\n"," '4.7',\n"," 'F2',\n"," '0.2.5',\n"," 'A3',\n"," 'D3',\n"," 'F2',\n"," '0.2',\n"," 'F3',\n"," 'A3',\n"," 'F2',\n"," 'F2',\n"," 'F2',\n"," '10.2',\n"," '0.5',\n"," 'F3',\n"," 'F3',\n"," '5.10',\n"," 'B-3',\n"," 'D4',\n"," 'F3',\n"," '10.2',\n"," 'F2',\n"," '3.5.10',\n"," '7.10',\n"," 'F3',\n"," '3.5.10',\n"," '7.10',\n"," 'F4',\n"," '3.7.10',\n"," '5.7',\n"," 'F3',\n"," '4.5',\n"," 'D5',\n"," '3.6',\n"," 'A4',\n"," 'F4',\n"," '3.6',\n"," '9.0.3',\n"," 'F#4',\n"," 'F3',\n"," 'F2',\n"," 'B-4',\n"," 'G3',\n"," 'F4',\n"," 'C4',\n"," '9.11.4',\n"," 'F#3',\n"," '7.10',\n"," '0.5',\n"," '9.2',\n"," '7.9.0',\n"," '1.3.8',\n"," 'A3',\n"," '1.3',\n"," 'B-5',\n"," 'A5',\n"," '2.7.8',\n"," 'G#3',\n"," '6.7.0',\n"," '0',\n"," 'C#4',\n"," '6.10',\n"," '6',\n"," '0.5',\n"," '4.9',\n"," '11.4',\n"," '3.6.8',\n"," '6.8',\n"," '1.7',\n"," '1.7',\n"," 'E-2',\n"," 'B-2',\n"," 'G3',\n"," '11.2',\n"," 'F3',\n"," 'B3',\n"," '8.11',\n"," '10.1',\n"," 'G4',\n"," 'E5',\n"," 'G5',\n"," '9.0.3',\n"," 'F#4',\n"," 'E-5',\n"," '8.11',\n"," 'F4',\n"," 'B-4',\n"," '4.7',\n"," 'C#5',\n"," 'E4',\n"," '6.9.0',\n"," 'E-5',\n"," 'E-4',\n"," '0.5',\n"," 'F4',\n"," 'C4',\n"," '9.2',\n"," 'A4',\n"," 'C5',\n"," 'A4',\n"," 'F4',\n"," '11.4',\n"," 'B4',\n"," 'F3',\n"," 'F4',\n"," 'C3',\n"," '7.11',\n"," 'C4',\n"," 'B3',\n"," 'G3',\n"," 'B-3',\n"," 'C4',\n"," 'B-3',\n"," 'G3',\n"," 'G#3',\n"," 'A3',\n"," 'F2',\n"," 'E-3',\n"," 'D4',\n"," 'F#4',\n"," 'A4',\n"," 'D5',\n"," 'F#5',\n"," '0.2',\n"," 'F4',\n"," 'E5',\n"," 'A4',\n"," 'A5',\n"," 'F3',\n"," 'A4',\n"," 'E5',\n"," 'B-3',\n"," 'A4',\n"," '9.10',\n"," '9.1.4',\n"," '9.1',\n"," 'E5',\n"," 'B-3',\n"," 'B-3',\n"," '9.1.4',\n"," 'C#4',\n"," 'G4',\n"," 'A3',\n"," 'D4',\n"," 'E-3',\n"," 'E-3',\n"," 'F2',\n"," '6.9',\n"," 'E-3',\n"," 'C#4',\n"," 'G3',\n"," '0.2.5',\n"," 'F5',\n"," '0.2',\n"," 'D5',\n"," 'E-5',\n"," 'F5',\n"," 'D5',\n"," 'F3',\n"," 'F4',\n"," 'F4',\n"," 'G4',\n"," 'G4',\n"," '0.2',\n"," 'A4',\n"," 'A4',\n"," 'B-4',\n"," 'B-4',\n"," '8.11.2',\n"," 'B4',\n"," 'B4',\n"," 'D5',\n"," 'D5',\n"," 'F3',\n"," '4.5',\n"," 'F5',\n"," '8',\n"," '8',\n"," '10',\n"," 'D4',\n"," 'G#3',\n"," 'B3',\n"," 'B5',\n"," 'B4',\n"," '1',\n"," '2',\n"," 'C6',\n"," 'B-5',\n"," 'B-4',\n"," '11.2',\n"," 'B5',\n"," '8',\n"," 'F3',\n"," 'A4',\n"," 'A5',\n"," '9.0',\n"," 'F3',\n"," 'E-4',\n"," 'A4',\n"," 'F3',\n"," '3.7',\n"," 'F3',\n"," 'C#4',\n"," 'E4',\n"," 'B-3',\n"," 'F3',\n"," '4.7',\n"," '3.6',\n"," '2.5',\n"," '1.4',\n"," 'E-5',\n"," '10.1',\n"," '0.4',\n"," 'E4',\n"," '11.2',\n"," '10.1',\n"," '9.0',\n"," 'F3',\n"," 'B-4',\n"," 'G#4',\n"," '5.9',\n"," '9.2',\n"," 'F3',\n"," 'F4',\n"," 'D4',\n"," 'D4',\n"," 'A3',\n"," '0.2',\n"," 'F3',\n"," 'A5',\n"," 'B5',\n"," 'G#5',\n"," 'B-5',\n"," 'A5',\n"," '10.2',\n"," 'B-5',\n"," 'G5',\n"," 'F4',\n"," 'F3',\n"," 'F5',\n"," 'D5',\n"," '10.2',\n"," '0.6',\n"," 'F5',\n"," 'F4',\n"," '6.9.0',\n"," 'F3',\n"," 'B-5',\n"," 'B-4',\n"," 'F5',\n"," 'F3',\n"," '10.3',\n"," '7.10',\n"," 'F4',\n"," '3.5',\n"," 'F3',\n"," '3.5.10',\n"," '3.7.10',\n"," 'F6',\n"," 'E-4',\n"," 'B-3',\n"," 'F4',\n"," 'F3',\n"," '10.3',\n"," 'G4',\n"," 'D4',\n"," '9.2',\n"," '2',\n"," 'F3',\n"," 'E4',\n"," 'D5',\n"," 'E-4',\n"," 'F4',\n"," '2',\n"," 'F3',\n"," '2.5',\n"," 'C4',\n"," '10.0.5',\n"," 'A3',\n"," '9.11.4',\n"," 'G3',\n"," '5.10',\n"," '0.5',\n"," 'C5',\n"," '3.5',\n"," 'C4',\n"," 'G#4',\n"," '6.10.1',\n"," '0.5',\n"," '5.9',\n"," 'G4',\n"," '4.8.11',\n"," 'F#4',\n"," 'F4',\n"," 'B-4',\n"," '3.7',\n"," 'F#5',\n"," 'D5',\n"," 'A4',\n"," 'E4',\n"," 'F5',\n"," '7.10.11',\n"," 'C3',\n"," '3.7',\n"," 'B-4',\n"," 'D4',\n"," 'E-4',\n"," 'G4',\n"," 'G3',\n"," 'E-4',\n"," 'G4',\n"," 'D4',\n"," 'F2',\n"," 'D4',\n"," 'F#4',\n"," 'A3',\n"," 'E-3',\n"," 'A3',\n"," 'D4',\n"," 'A3',\n"," '0.3.7',\n"," 'D4',\n"," '11.2.4',\n"," '8.0',\n"," 'C5',\n"," 'F#3',\n"," '4.7',\n"," '7.10.2',\n"," 'G2',\n"," 'F#4',\n"," 'D4',\n"," 'F#3',\n"," 'D4',\n"," 'G4',\n"," 'G3',\n"," '5.9',\n"," 'G2',\n"," '2.5.9',\n"," 'E-3',\n"," 'F#3',\n"," '10.2.5',\n"," 'G4',\n"," 'G3',\n"," 'F#3',\n"," 'F3',\n"," '10.2',\n"," 'F4',\n"," '10.0.2',\n"," 'E3',\n"," '9.0.2',\n"," '0.6',\n"," '8.1',\n"," 'D4',\n"," 'E-4',\n"," 'E4',\n"," '3.7.11',\n"," 'F#2',\n"," 'E-3',\n"," '2.5.7',\n"," 'A3',\n"," '2.7',\n"," '2.3',\n"," 'C#4',\n"," 'E-4',\n"," ...]"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["This list consists of note pitches (e.g. 'B-4' for Bflat note in Octave Number 4, 'F4' for F note in Octave Number 4) and chords (represented as several integers separated by dots).\n","\n","Now that we have a list of notes and chords, we will use these to create both the input features and the target variable for training purposes.\n","\n","Each input feature is arbitrarily set at 100 consecutive notes and the target variable is the note which comes directly after (i.e. the 101th note). The output variable is what the model will try to predict and be scored against during training."],"metadata":{"id":"LkGr9cYXekR6"},"id":"LkGr9cYXekR6"},{"cell_type":"code","metadata":{"id":"bb5f44be"},"source":["def create_input_output(notes, unique_note_count):\n","    # Extract and sort all unique pitches from the extracted note list above\n","    pitchnames = sorted(set(item for item in notes))\n","    # Create a dictionary to map pitches to integers\n","    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n","\n","    network_input = []\n","    network_output = []\n","\n","    # Predict the 101th note using 100 notes at a time\n","    sequence_length = 100\n","\n","    # create input note sequences and the corresponding next note for training purposes\n","    for i in range(0, len(notes) - sequence_length, 1):\n","        sequence_in = notes[i:i + sequence_length]\n","        sequence_out = notes[i + sequence_length]\n","        network_input.append([note_to_int[char] for char in sequence_in])\n","        network_output.append(note_to_int[sequence_out])\n","\n","    input_count = len(network_input)\n","    # reshape the input into a format compatible with LSTM layers\n","    network_input = np.reshape(network_input, (input_count, sequence_length, 1))\n","    # normalize input\n","    network_input = network_input / float(unique_note_count)\n","    # one hot encode the output vector\n","    network_output = np_utils.to_categorical(network_output)\n","\n","    return (network_input, network_output)"],"id":"bb5f44be","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cprFEFrCKxA_","executionInfo":{"status":"ok","timestamp":1639667904867,"user_tz":-480,"elapsed":327,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}}},"source":["# get the full length of notes extracted\n","unique_note_count = len(set(notes))"],"id":"cprFEFrCKxA_","execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"647unK0BBdL4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639200747506,"user_tz":-480,"elapsed":270,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}},"outputId":"1cc52945-1651-45cb-8f59-00d18c0921aa"},"source":["# Create input and output for RNN training\n","# Input - for each record, a list of 100 notes normalized\n","# Output - for each record, a one-hot encoded version of the output note\n","create_input_output(notes, unique_note_count)"],"id":"647unK0BBdL4","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[[0.8       ],\n","         [0.95072464],\n","         [0.02028986],\n","         ...,\n","         [0.51304348],\n","         [0.28115942],\n","         [0.9826087 ]],\n"," \n","        [[0.95072464],\n","         [0.02028986],\n","         [0.02028986],\n","         ...,\n","         [0.28115942],\n","         [0.9826087 ],\n","         [0.95072464]],\n"," \n","        [[0.02028986],\n","         [0.02028986],\n","         [0.95072464],\n","         ...,\n","         [0.9826087 ],\n","         [0.95072464],\n","         [0.06376812]],\n"," \n","        ...,\n"," \n","        [[0.89275362],\n","         [0.59130435],\n","         [0.85217391],\n","         ...,\n","         [0.88115942],\n","         [0.95942029],\n","         [0.80869565]],\n"," \n","        [[0.59130435],\n","         [0.85217391],\n","         [0.21449275],\n","         ...,\n","         [0.95942029],\n","         [0.80869565],\n","         [0.86376812]],\n"," \n","        [[0.85217391],\n","         [0.21449275],\n","         [0.9884058 ],\n","         ...,\n","         [0.80869565],\n","         [0.86376812],\n","         [0.86376812]]]), array([[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### Create Neural Network Architecture\n","\n","The RNN model chosen is [LSTM (Long Short Term Memory)](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) which is capable of learning long-term dependencies.\n","\n","Our model consists of:\n","- Stacked LSTM layers (2 layers) with each layer consisting of 128 hidden nodes\n","- A dense layer consisting of 256 nodes using 'relu' (rectified linear unit) activation\n","- An output dense layer with the same node count as all the possible unique note we have parsed\n","\n","Categorical cross entropy is chosen as the loss function because our output is essentially a multi-class classification."],"metadata":{"id":"Z6GzorhPGxcj"},"id":"Z6GzorhPGxcj"},{"cell_type":"code","metadata":{"id":"EsudSknIyLmQ","executionInfo":{"status":"ok","timestamp":1639668692711,"user_tz":-480,"elapsed":338,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}}},"source":["def create_network(network_input, unique_note_count):\n","    # create the structure of the neural network\n","    model = Sequential()\n","    model.add(LSTM(\n","        128,\n","        input_shape=(network_input.shape[1], network_input.shape[2]), #100 by 1\n","        recurrent_dropout=0.2,\n","        return_sequences=True #return_sequences = True to feed the output of LSTM array to another LSTM layer \n","    ))\n","    model.add(LSTM(128, return_sequences=False))\n","    model.add(BatchNorm())\n","    model.add(Dense(256, activation='relu'))\n","    model.add(BatchNorm())\n","    model.add(Dense(unique_note_count, activation='softmax'))\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","    return model"],"id":"EsudSknIyLmQ","execution_count":23,"outputs":[]},{"cell_type":"code","source":["model = create_network(network_input, unique_note_count)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tHWzSyKf_QG3","executionInfo":{"status":"ok","timestamp":1639668697284,"user_tz":-480,"elapsed":1164,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}},"outputId":"f5fe6701-4775-41fc-d603-139cfb17f1d1"},"id":"tHWzSyKf_QG3","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 100, 128)          66560     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 128)               131584    \n","                                                                 \n"," batch_normalization (BatchN  (None, 128)              512       \n"," ormalization)                                                   \n","                                                                 \n"," dense (Dense)               (None, 256)               33024     \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 256)              1024      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_1 (Dense)             (None, 345)               88665     \n","                                                                 \n","=================================================================\n","Total params: 321,369\n","Trainable params: 320,601\n","Non-trainable params: 768\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### Train Model\n","\n","Now we can begin feeding our input and output into the training model. We are using 400 epochs for this training.\n","\n","At every single training epoch, we will assess the loss value generated and save the weights if the loss is better (lower in value) compared to the previous epoch. This way we can ensure that we only save progressively better weights and use them as checkpoints to assess how they are performing."],"metadata":{"id":"uTX7EWwVHQG1"},"id":"uTX7EWwVHQG1"},{"cell_type":"code","metadata":{"id":"58c325ea"},"source":["def train(model, network_input, network_output):\n","    # Create filepath to store the weights of the various epochs\n","    filepath = \"/content/drive/MyDrive/Colab Notebooks/model/weights/weights-{epoch:02d}-{loss:.4f}.hdf5\"\n","    checkpoint = ModelCheckpoint(\n","        filepath,\n","        monitor='loss',\n","        verbose=0,\n","        save_best_only=True, #save weights only if the epoch results in lower loss\n","        mode='min'\n","    )\n","    callbacks_list = [checkpoint]\n","\n","    # Run the model with 400 epochs\n","    model.fit(network_input, network_output, epochs=400, batch_size=32, callbacks=callbacks_list)"],"id":"58c325ea","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(model, network_input, network_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnJIBknq_8GW","outputId":"b27fa49d-2231-4d4c-ade4-5996a35f62ef"},"id":"gnJIBknq_8GW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/400\n","129/129 [==============================] - 47s 331ms/step - loss: 5.4835\n","Epoch 2/400\n","129/129 [==============================] - 43s 330ms/step - loss: 5.1335\n","Epoch 3/400\n","129/129 [==============================] - 43s 331ms/step - loss: 4.8281\n","Epoch 4/400\n","129/129 [==============================] - 43s 333ms/step - loss: 4.7018\n","Epoch 5/400\n","129/129 [==============================] - 43s 332ms/step - loss: 4.5892\n","Epoch 6/400\n","129/129 [==============================] - 43s 333ms/step - loss: 4.5397\n","Epoch 7/400\n","129/129 [==============================] - 43s 334ms/step - loss: 4.4731\n","Epoch 8/400\n","129/129 [==============================] - 43s 333ms/step - loss: 4.4296\n","Epoch 9/400\n","129/129 [==============================] - 43s 331ms/step - loss: 4.3898\n","Epoch 10/400\n","129/129 [==============================] - 43s 333ms/step - loss: 4.3583\n","Epoch 11/400\n","129/129 [==============================] - 43s 333ms/step - loss: 4.3539\n","Epoch 12/400\n","129/129 [==============================] - 43s 332ms/step - loss: 4.2801\n","Epoch 13/400\n","129/129 [==============================] - 43s 333ms/step - loss: 4.2381\n","Epoch 14/400\n","129/129 [==============================] - 43s 331ms/step - loss: 4.2059\n","Epoch 15/400\n","129/129 [==============================] - 43s 333ms/step - loss: 4.1642\n","Epoch 16/400\n","129/129 [==============================] - 43s 333ms/step - loss: 4.1364\n","Epoch 17/400\n","129/129 [==============================] - 43s 331ms/step - loss: 4.0884\n","Epoch 18/400\n","129/129 [==============================] - 43s 332ms/step - loss: 4.0775\n","Epoch 19/400\n","129/129 [==============================] - 43s 332ms/step - loss: 4.0144\n","Epoch 20/400\n","129/129 [==============================] - 43s 331ms/step - loss: 3.9930\n","Epoch 21/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.9631\n","Epoch 22/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.9261\n","Epoch 23/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.8762\n","Epoch 24/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.8493\n","Epoch 25/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.8136\n","Epoch 26/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.7907\n","Epoch 27/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.7433\n","Epoch 28/400\n","129/129 [==============================] - 43s 334ms/step - loss: 3.6954\n","Epoch 29/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.6729\n","Epoch 30/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.6285\n","Epoch 31/400\n","129/129 [==============================] - 43s 330ms/step - loss: 3.6159\n","Epoch 32/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.5665\n","Epoch 33/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.5326\n","Epoch 34/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.4946\n","Epoch 35/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.4612\n","Epoch 36/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.4335\n","Epoch 37/400\n","129/129 [==============================] - 43s 337ms/step - loss: 3.3916\n","Epoch 38/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.3874\n","Epoch 39/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.3506\n","Epoch 40/400\n","129/129 [==============================] - 43s 335ms/step - loss: 3.3137\n","Epoch 41/400\n","129/129 [==============================] - 43s 335ms/step - loss: 3.2620\n","Epoch 42/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.2687\n","Epoch 43/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.2159\n","Epoch 44/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.1965\n","Epoch 45/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.1811\n","Epoch 46/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.1250\n","Epoch 47/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.0837\n","Epoch 48/400\n","129/129 [==============================] - 43s 334ms/step - loss: 3.0797\n","Epoch 49/400\n","129/129 [==============================] - 43s 333ms/step - loss: 3.0748\n","Epoch 50/400\n","129/129 [==============================] - 43s 331ms/step - loss: 3.0214\n","Epoch 51/400\n","129/129 [==============================] - 43s 332ms/step - loss: 3.0076\n","Epoch 52/400\n","129/129 [==============================] - 43s 331ms/step - loss: 2.9659\n","Epoch 53/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.9293\n","Epoch 54/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.9476\n","Epoch 55/400\n","129/129 [==============================] - 43s 330ms/step - loss: 2.8867\n","Epoch 56/400\n","129/129 [==============================] - 43s 330ms/step - loss: 2.8617\n","Epoch 57/400\n","129/129 [==============================] - 43s 335ms/step - loss: 2.8408\n","Epoch 58/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.8366\n","Epoch 59/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.8044\n","Epoch 60/400\n","129/129 [==============================] - 43s 331ms/step - loss: 2.7750\n","Epoch 61/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.7418\n","Epoch 62/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.7537\n","Epoch 63/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.7129\n","Epoch 64/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.6635\n","Epoch 65/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.6692\n","Epoch 66/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.6537\n","Epoch 67/400\n","129/129 [==============================] - 43s 331ms/step - loss: 2.6262\n","Epoch 68/400\n","129/129 [==============================] - 43s 334ms/step - loss: 2.5911\n","Epoch 69/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.5870\n","Epoch 70/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.5609\n","Epoch 71/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.5708\n","Epoch 72/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.5332\n","Epoch 73/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.5107\n","Epoch 74/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.4812\n","Epoch 75/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.4853\n","Epoch 76/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.4927\n","Epoch 77/400\n","129/129 [==============================] - 43s 334ms/step - loss: 2.4352\n","Epoch 78/400\n","129/129 [==============================] - 43s 330ms/step - loss: 2.4434\n","Epoch 79/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.4277\n","Epoch 80/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.3946\n","Epoch 81/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.3615\n","Epoch 82/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.3547\n","Epoch 83/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.3661\n","Epoch 84/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.3257\n","Epoch 85/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.3378\n","Epoch 86/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.3028\n","Epoch 87/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.2931\n","Epoch 88/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.2541\n","Epoch 89/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.2388\n","Epoch 90/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.2023\n","Epoch 91/400\n","129/129 [==============================] - 43s 334ms/step - loss: 2.2461\n","Epoch 92/400\n","129/129 [==============================] - 43s 331ms/step - loss: 2.2241\n","Epoch 93/400\n","129/129 [==============================] - 43s 331ms/step - loss: 2.1950\n","Epoch 94/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.1851\n","Epoch 95/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.1723\n","Epoch 96/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.1434\n","Epoch 97/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.1057\n","Epoch 98/400\n","129/129 [==============================] - 43s 334ms/step - loss: 2.1133\n","Epoch 99/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.1316\n","Epoch 100/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.0635\n","Epoch 101/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.0564\n","Epoch 102/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.0864\n","Epoch 103/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.0685\n","Epoch 104/400\n","129/129 [==============================] - 43s 331ms/step - loss: 2.1210\n","Epoch 105/400\n","129/129 [==============================] - 43s 334ms/step - loss: 2.0290\n","Epoch 106/400\n","129/129 [==============================] - 43s 334ms/step - loss: 2.0269\n","Epoch 107/400\n","129/129 [==============================] - 43s 333ms/step - loss: 2.0336\n","Epoch 108/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.9948\n","Epoch 109/400\n","129/129 [==============================] - 43s 332ms/step - loss: 2.0106\n","Epoch 110/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.9815\n","Epoch 111/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.9650\n","Epoch 112/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.9266\n","Epoch 113/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.8924\n","Epoch 114/400\n","129/129 [==============================] - 43s 332ms/step - loss: 1.9079\n","Epoch 115/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.9216\n","Epoch 116/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.9204\n","Epoch 117/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.8861\n","Epoch 118/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.8497\n","Epoch 119/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.8449\n","Epoch 120/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.9069\n","Epoch 121/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.8129\n","Epoch 122/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.8694\n","Epoch 123/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.8086\n","Epoch 124/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.8307\n","Epoch 125/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.7871\n","Epoch 126/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.7614\n","Epoch 127/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.7813\n","Epoch 128/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.7419\n","Epoch 129/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.7172\n","Epoch 130/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.7284\n","Epoch 131/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.7000\n","Epoch 132/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.8188\n","Epoch 133/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.6699\n","Epoch 134/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.6856\n","Epoch 135/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.6554\n","Epoch 136/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.6252\n","Epoch 137/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.6056\n","Epoch 138/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.6165\n","Epoch 139/400\n","129/129 [==============================] - 43s 330ms/step - loss: 1.6605\n","Epoch 140/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.5871\n","Epoch 141/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.5727\n","Epoch 142/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.5515\n","Epoch 143/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.5407\n","Epoch 144/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.5378\n","Epoch 145/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.5170\n","Epoch 146/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.5000\n","Epoch 147/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.4671\n","Epoch 148/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.5955\n","Epoch 149/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.4444\n","Epoch 150/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.4345\n","Epoch 151/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.4682\n","Epoch 152/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.4418\n","Epoch 153/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.4402\n","Epoch 154/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.3342\n","Epoch 155/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.3568\n","Epoch 156/400\n","129/129 [==============================] - 43s 332ms/step - loss: 1.3376\n","Epoch 157/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.3547\n","Epoch 158/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.2939\n","Epoch 159/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.3001\n","Epoch 160/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.3502\n","Epoch 161/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.2515\n","Epoch 162/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.2550\n","Epoch 163/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.2656\n","Epoch 164/400\n","129/129 [==============================] - 43s 336ms/step - loss: 1.2512\n","Epoch 165/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.2096\n","Epoch 166/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.2242\n","Epoch 167/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.1727\n","Epoch 168/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.2033\n","Epoch 169/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.1675\n","Epoch 170/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.2074\n","Epoch 171/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.2231\n","Epoch 172/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.2343\n","Epoch 173/400\n","129/129 [==============================] - 43s 335ms/step - loss: 1.1321\n","Epoch 174/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.1500\n","Epoch 175/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.0812\n","Epoch 176/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.1975\n","Epoch 177/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.1086\n","Epoch 178/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.1358\n","Epoch 179/400\n","129/129 [==============================] - 44s 338ms/step - loss: 1.0267\n","Epoch 180/400\n","129/129 [==============================] - 44s 338ms/step - loss: 0.9890\n","Epoch 181/400\n","129/129 [==============================] - 43s 336ms/step - loss: 0.9948\n","Epoch 182/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.9981\n","Epoch 183/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.9921\n","Epoch 184/400\n","129/129 [==============================] - 43s 333ms/step - loss: 1.0575\n","Epoch 185/400\n","129/129 [==============================] - 43s 334ms/step - loss: 1.0272\n","Epoch 186/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.9389\n","Epoch 187/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.9155\n","Epoch 188/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.9139\n","Epoch 189/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.9434\n","Epoch 190/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.9184\n","Epoch 191/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.9367\n","Epoch 192/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.9326\n","Epoch 193/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.8875\n","Epoch 194/400\n","129/129 [==============================] - 43s 336ms/step - loss: 0.8414\n","Epoch 195/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.8481\n","Epoch 196/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.8131\n","Epoch 197/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.8216\n","Epoch 198/400\n","129/129 [==============================] - 43s 331ms/step - loss: 0.9396\n","Epoch 199/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.8320\n","Epoch 200/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.8204\n","Epoch 201/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.9208\n","Epoch 202/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.9545\n","Epoch 203/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.8169\n","Epoch 204/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.8069\n","Epoch 205/400\n","129/129 [==============================] - 43s 335ms/step - loss: 0.7625\n","Epoch 206/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.8916\n","Epoch 207/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.7359\n","Epoch 208/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.8744\n","Epoch 209/400\n","129/129 [==============================] - 43s 331ms/step - loss: 0.7802\n","Epoch 210/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.6744\n","Epoch 211/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.7549\n","Epoch 212/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.7040\n","Epoch 213/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.6234\n","Epoch 214/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.6515\n","Epoch 215/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.6862\n","Epoch 216/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.7477\n","Epoch 217/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.6876\n","Epoch 218/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.6918\n","Epoch 219/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.5998\n","Epoch 220/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.5766\n","Epoch 221/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.5963\n","Epoch 222/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.7169\n","Epoch 223/400\n","129/129 [==============================] - 43s 330ms/step - loss: 0.6718\n","Epoch 224/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.6848\n","Epoch 225/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.6616\n","Epoch 226/400\n","129/129 [==============================] - 43s 331ms/step - loss: 0.6636\n","Epoch 227/400\n","129/129 [==============================] - 43s 331ms/step - loss: 0.6117\n","Epoch 228/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.5958\n","Epoch 229/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.5385\n","Epoch 230/400\n","129/129 [==============================] - 43s 335ms/step - loss: 0.5995\n","Epoch 231/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.5644\n","Epoch 232/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.5010\n","Epoch 233/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.6499\n","Epoch 234/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.7444\n","Epoch 235/400\n","129/129 [==============================] - 43s 332ms/step - loss: 0.5202\n","Epoch 236/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.5543\n","Epoch 237/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.7053\n","Epoch 238/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.5638\n","Epoch 239/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.4633\n","Epoch 240/400\n","129/129 [==============================] - 43s 335ms/step - loss: 0.4473\n","Epoch 241/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.4406\n","Epoch 242/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.4511\n","Epoch 243/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.4762\n","Epoch 244/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.5341\n","Epoch 245/400\n","129/129 [==============================] - 43s 333ms/step - loss: 0.4514\n","Epoch 246/400\n","129/129 [==============================] - 43s 330ms/step - loss: 0.4409\n","Epoch 247/400\n","129/129 [==============================] - 42s 328ms/step - loss: 0.4719\n","Epoch 248/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.8402\n","Epoch 249/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.4854\n","Epoch 250/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.4450\n","Epoch 251/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.4340\n","Epoch 252/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.4421\n","Epoch 253/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.5267\n","Epoch 254/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.4244\n","Epoch 255/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.5327\n","Epoch 256/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.4119\n","Epoch 257/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.5792\n","Epoch 258/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3743\n","Epoch 259/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.5820\n","Epoch 260/400\n","129/129 [==============================] - 42s 324ms/step - loss: 0.4616\n","Epoch 261/400\n","129/129 [==============================] - 42s 324ms/step - loss: 0.4016\n","Epoch 262/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3706\n","Epoch 263/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3508\n","Epoch 264/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.3720\n","Epoch 265/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.3767\n","Epoch 266/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.3829\n","Epoch 267/400\n","129/129 [==============================] - 43s 334ms/step - loss: 0.4566\n","Epoch 268/400\n","129/129 [==============================] - 42s 329ms/step - loss: 0.4488\n","Epoch 269/400\n","129/129 [==============================] - 42s 328ms/step - loss: 0.4012\n","Epoch 270/400\n","129/129 [==============================] - 42s 329ms/step - loss: 0.3565\n","Epoch 271/400\n","129/129 [==============================] - 43s 330ms/step - loss: 0.3775\n","Epoch 272/400\n","129/129 [==============================] - 43s 330ms/step - loss: 0.5160\n","Epoch 273/400\n","129/129 [==============================] - 42s 329ms/step - loss: 0.3452\n","Epoch 274/400\n","129/129 [==============================] - 42s 329ms/step - loss: 0.3114\n","Epoch 275/400\n","129/129 [==============================] - 42s 328ms/step - loss: 0.3079\n","Epoch 276/400\n","129/129 [==============================] - 42s 328ms/step - loss: 0.3574\n","Epoch 277/400\n","129/129 [==============================] - 42s 328ms/step - loss: 0.5158\n","Epoch 278/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.3904\n","Epoch 279/400\n","129/129 [==============================] - 42s 328ms/step - loss: 0.3418\n","Epoch 280/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3558\n","Epoch 281/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.3173\n","Epoch 282/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.3315\n","Epoch 283/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2758\n","Epoch 284/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.4813\n","Epoch 285/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3379\n","Epoch 286/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2665\n","Epoch 287/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.3081\n","Epoch 288/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3271\n","Epoch 289/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.3064\n","Epoch 290/400\n","129/129 [==============================] - 42s 328ms/step - loss: 0.2657\n","Epoch 291/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3028\n","Epoch 292/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.4564\n","Epoch 293/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3150\n","Epoch 294/400\n","129/129 [==============================] - 42s 329ms/step - loss: 0.3623\n","Epoch 295/400\n","129/129 [==============================] - 42s 328ms/step - loss: 0.2874\n","Epoch 296/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3162\n","Epoch 297/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3821\n","Epoch 298/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2848\n","Epoch 299/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3752\n","Epoch 300/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3045\n","Epoch 301/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3196\n","Epoch 302/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3247\n","Epoch 303/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2552\n","Epoch 304/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2901\n","Epoch 305/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2443\n","Epoch 306/400\n","129/129 [==============================] - 42s 324ms/step - loss: 0.2968\n","Epoch 307/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2449\n","Epoch 308/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2487\n","Epoch 309/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2198\n","Epoch 310/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3093\n","Epoch 311/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2085\n","Epoch 312/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2644\n","Epoch 313/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3108\n","Epoch 314/400\n","129/129 [==============================] - 42s 324ms/step - loss: 0.4281\n","Epoch 315/400\n","129/129 [==============================] - 42s 324ms/step - loss: 0.2675\n","Epoch 316/400\n","129/129 [==============================] - 42s 324ms/step - loss: 0.3510\n","Epoch 317/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2804\n","Epoch 318/400\n","129/129 [==============================] - 42s 329ms/step - loss: 0.2508\n","Epoch 319/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.3066\n","Epoch 320/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2746\n","Epoch 321/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2615\n","Epoch 322/400\n","129/129 [==============================] - 42s 324ms/step - loss: 0.2330\n","Epoch 323/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3070\n","Epoch 324/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2418\n","Epoch 325/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2811\n","Epoch 326/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2379\n","Epoch 327/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2707\n","Epoch 328/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3020\n","Epoch 329/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2184\n","Epoch 330/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2018\n","Epoch 331/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2255\n","Epoch 332/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3292\n","Epoch 333/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2640\n","Epoch 334/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2678\n","Epoch 335/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2339\n","Epoch 336/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2935\n","Epoch 337/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1977\n","Epoch 338/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2056\n","Epoch 339/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3387\n","Epoch 340/400\n","129/129 [==============================] - 42s 324ms/step - loss: 0.2661\n","Epoch 341/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2119\n","Epoch 342/400\n","129/129 [==============================] - 42s 329ms/step - loss: 0.1896\n","Epoch 343/400\n","129/129 [==============================] - 42s 329ms/step - loss: 0.1822\n","Epoch 344/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.2896\n","Epoch 345/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2115\n","Epoch 346/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2908\n","Epoch 347/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1763\n","Epoch 348/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3636\n","Epoch 349/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2316\n","Epoch 350/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2789\n","Epoch 351/400\n","129/129 [==============================] - 42s 324ms/step - loss: 0.2339\n","Epoch 352/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3170\n","Epoch 353/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.4297\n","Epoch 354/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1983\n","Epoch 355/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1868\n","Epoch 356/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1955\n","Epoch 357/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1521\n","Epoch 358/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2171\n","Epoch 359/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2052\n","Epoch 360/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.3292\n","Epoch 361/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1880\n","Epoch 362/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2180\n","Epoch 363/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1800\n","Epoch 364/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.2777\n","Epoch 365/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.1917\n","Epoch 366/400\n","129/129 [==============================] - 43s 330ms/step - loss: 0.2272\n","Epoch 367/400\n","129/129 [==============================] - 42s 329ms/step - loss: 0.2316\n","Epoch 368/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1945\n","Epoch 369/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.4234\n","Epoch 370/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.2221\n","Epoch 371/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.1933\n","Epoch 372/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2904\n","Epoch 373/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1762\n","Epoch 374/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2518\n","Epoch 375/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1664\n","Epoch 376/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1517\n","Epoch 377/400\n","129/129 [==============================] - 42s 327ms/step - loss: 0.2544\n","Epoch 378/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.3429\n","Epoch 379/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.4028\n","Epoch 380/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.2332\n","Epoch 381/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1754\n","Epoch 382/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1449\n","Epoch 383/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1535\n","Epoch 384/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1819\n","Epoch 385/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1504\n","Epoch 386/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1929\n","Epoch 387/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1481\n","Epoch 388/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.5335\n","Epoch 389/400\n","129/129 [==============================] - 42s 325ms/step - loss: 0.1702\n","Epoch 390/400\n","129/129 [==============================] - 42s 326ms/step - loss: 0.1480\n","Epoch 391/400\n","129/129 [==============================] - 42s 328ms/step - loss: 0.1528\n","Epoch 392/400\n","129/129 [==============================] - 43s 330ms/step - loss: 0.2628\n","Epoch 393/400\n","106/129 [=======================>......] - ETA: 7s - loss: 0.1730"]}]},{"cell_type":"markdown","source":["### Prepare Prediction Input\n","\n","Building on the training input function from earlier in the notebook, we will repurpose it to create 2 different inputs:\n","- Network_input: the list of 100-note inputs to randomize for prediction\n","- Normalized_input: to recreate the training model architecture"],"metadata":{"id":"sDLAD1co8qSS"},"id":"sDLAD1co8qSS"},{"cell_type":"code","metadata":{"id":"20269e41","executionInfo":{"status":"ok","timestamp":1639672732355,"user_tz":-480,"elapsed":297,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}}},"source":["def prepare_prediction_input(notes, pitchnames, unique_note_count):\n","    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n","\n","    sequence_length = 100\n","    network_input = []\n","    for i in range(0, len(notes) - sequence_length, 1):\n","        sequence_in = notes[i:i + sequence_length]\n","        network_input.append([note_to_int[char] for char in sequence_in])\n","\n","    input_count = len(network_input)\n","\n","    # reshape the input into a format compatible with LSTM layers\n","    normalized_input = np.reshape(network_input, (input_count, sequence_length, 1))\n","    # normalize input\n","    normalized_input = normalized_input / float(unique_note_count)\n","\n","    return (network_input, normalized_input)"],"id":"20269e41","execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["### Generate Notes\n","\n","We will generate 500 notes which will give us a song of about 2 minutes to listen to. To start us off, we are randomly selecting one of our 100-note inputs from the training"],"metadata":{"id":"42oM9QxTRUyO"},"id":"42oM9QxTRUyO"},{"cell_type":"code","metadata":{"id":"99db9c98","executionInfo":{"status":"ok","timestamp":1639672735137,"user_tz":-480,"elapsed":1,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}}},"source":["def generate_notes(model, network_input, pitchnames, unique_note_count):\n","    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n","\n","    # pick a random 100-note training input to start off our prediction\n","    start = np.random.randint(0, len(network_input)-1)\n","    pattern = network_input[start]\n","    prediction_output = []\n","\n","    # generate 500 notes\n","    for note_index in range(500):\n","        # normalize 1 record of prediction input and predict the output\n","        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n","        prediction_input = prediction_input / float(unique_note_count)\n","        prediction = model.predict(prediction_input, verbose=0)\n","\n","        # Return the index of the output vector with the highest value\n","        index = np.argmax(prediction)\n","        # Map the predicted integer back to the corresponding note \n","        result = int_to_note[index]\n","        # Store the predicted note into an output list and append the predicted note to the initial training input\n","        prediction_output.append(result)\n","        pattern.append(index)\n","        # Drop the first note and keep the latest 100 note for the next note prediction cycle \n","        pattern = pattern[1:len(pattern)]\n","\n","    return prediction_output"],"id":"99db9c98","execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["### Create Output Midi\n","\n","Now we need to string back together the predicted notes into a midi song structure. \n","\n","To assess how training progress across epochs, we will load the weights at epoch 1, 100, 204, 303 and 382 separately into the model. These will give us 5 song outputs to listen to."],"metadata":{"id":"5MFF-3mJPtKC"},"id":"5MFF-3mJPtKC"},{"cell_type":"code","metadata":{"id":"21325519","executionInfo":{"status":"ok","timestamp":1639672738255,"user_tz":-480,"elapsed":3,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}}},"source":["def create_midi(prediction_output):\n","    offset = 0 #offset is the time position in a song\n","    output_notes = []\n","\n","    # recreate note and chord\n","    for pattern in prediction_output:\n","        # if the prediction is a chord\n","        if ('.' in pattern) or pattern.isdigit():\n","            # for each note in the chord, break it apart and convert the normal order number back to actual note\n","            notes_in_chord = pattern.split('.')\n","            notes = []\n","            for current_note in notes_in_chord:\n","                new_note = note.Note(int(current_note))\n","                new_note.storedInstrument = instrument.Piano()\n","                notes.append(new_note)\n","            new_chord = chord.Chord(notes)\n","            new_chord.offset = offset\n","            output_notes.append(new_chord)\n","        # if the prediction is a note\n","        else:\n","            new_note = note.Note(pattern)\n","            new_note.offset = offset\n","            new_note.storedInstrument = instrument.Piano()\n","            output_notes.append(new_note)\n","\n","        # add time offset to indicate the position of the next note in the song.\n","        # If offset = 0, the next note will be played together with the first note instead of afterwards\n","        offset += 0.5\n","\n","    midi_stream = stream.Stream(output_notes)\n","\n","    # Indicate the name of the midi files to be created\n","    # midi_stream.write('midi', fp='/content/drive/MyDrive/Colab Notebooks/model/output_epoch1.mid')\n","    # midi_stream.write('midi', fp='/content/drive/MyDrive/Colab Notebooks/model/output_epoch100.mid')\n","    # midi_stream.write('midi', fp='/content/drive/MyDrive/Colab Notebooks/model/output_epoch204.mid')\n","    # midi_stream.write('midi', fp='/content/drive/MyDrive/Colab Notebooks/model/output_epoch303.mid')\n","    midi_stream.write('midi', fp='/content/drive/MyDrive/Colab Notebooks/model/output_epoch382.mid')"],"id":"21325519","execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["### String Generation End to End"],"metadata":{"id":"CXQtQI3SB-N7"},"id":"CXQtQI3SB-N7"},{"cell_type":"code","metadata":{"id":"b44321da","executionInfo":{"status":"ok","timestamp":1639672741611,"user_tz":-480,"elapsed":291,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}}},"source":["def generate_end_to_end():\n","    # Load the notes used to train the model\n","    with open('/content/drive/MyDrive/Colab Notebooks/model/data/notes', 'rb') as filepath:\n","        notes = pickle.load(filepath)\n","\n","    # Get all pitch names\n","    pitchnames = sorted(set(item for item in notes))\n","    unique_note_count = len(set(notes))\n","\n","    # Prepare prediction input\n","    network_input, normalized_input = prepare_prediction_input(notes, pitchnames, unique_note_count)\n","    \n","    # recreate rnn architecture that we use for traiing\n","    model = create_network(normalized_input, unique_note_count)\n","\n","    # Load the weights to each node in the model\n","    # model.load_weights('/content/drive/MyDrive/Colab Notebooks/model/weights/weights-01-5.4835.hdf5')\n","    # model.load_weights('/content/drive/MyDrive/Colab Notebooks/model/weights/weights-100-2.0635.hdf5')\n","    # model.load_weights('/content/drive/MyDrive/Colab Notebooks/model/weights/weights-204-0.8069.hdf5')\n","    # model.load_weights('/content/drive/MyDrive/Colab Notebooks/model/weights/weights-303-0.2552.hdf5')\n","    model.load_weights('/content/drive/MyDrive/Colab Notebooks/model/weights/weights-382-0.1449.hdf5')\n","    \n","    prediction_output = generate_notes(model, network_input, pitchnames, unique_note_count)\n","    create_midi(prediction_output)"],"id":"b44321da","execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9d2fa3f","executionInfo":{"status":"ok","timestamp":1639672782936,"user_tz":-480,"elapsed":37034,"user":{"displayName":"Martin Yong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRUYw1ZjAVEJTKgT4JxFpbZAUstcrVArgJoqY9=s64","userId":"09861846184435716836"}}},"source":["generate_end_to_end()"],"id":"d9d2fa3f","execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["Once the midi files are generated, we can use software such as garage band or convert it to mp3 via website such as [zamzar.com](https://www.zamzar.com/) to give it a listen."],"metadata":{"id":"p1vD5Nwe6Atg"},"id":"p1vD5Nwe6Atg"},{"cell_type":"markdown","source":["### Result\n","\n","From listening to the MIDI files, we can observe massive improvements across epochs: \n","- In epoch 1, 1 note is played over and over for the entirety of the song\n","- In epoch 100, the model has now learned to play more than 1 note although there are still instances of repetitive notes and absence of any chords\n","- In epoch 382, the model has learned to play chords and have little to no repetitive notes. However, all notes have the same duration and there are no pauses between notes"],"metadata":{"id":"hB5Nj6u0LNHz"},"id":"hB5Nj6u0LNHz"},{"cell_type":"markdown","source":["### Next Steps\n","1. Ingest rest notes (offsets) as inputs in order for the model to learn pauses in songs\n","2. Try to create structure of actual songs, e.g. verse-chorus-verse-chorus-bridge\n","3. Add an additional instrument, e.g. bass"],"metadata":{"id":"SJpDazYKOmOJ"},"id":"SJpDazYKOmOJ"}]}